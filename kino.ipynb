{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMERA PRUEBA\n",
    "No funciona bien por el return jsonify....return jsonify({'answer': response['answer']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['DEBUG'] = True\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=\"YOUR_OPENAI_API_KEY\")\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/api/query', methods=['POST'])\n",
    "def query():\n",
    "    document = request.files['document'].read().decode('utf-8')\n",
    "    question = request.form['question']\n",
    "\n",
    "    # Llamada a Langchain\n",
    "    response = qa_document_chain.run(input_document=document, question=question)\n",
    "\n",
    "    # Almacenar en la base de datos (a implementar)\n",
    "\n",
    "    return jsonify({'answer': response['answer']})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGUNDA PRUEBA\n",
    "Funciona bien por el siguiente cambio en el anterior script\n",
    "\n",
    "   # probando sin almacenar\n",
    "    return jsonify({'answer': response})\n",
    "\n",
    "\n",
    "    # Almacenar en la base de datos (a implementar)\n",
    "\n",
    "    # return jsonify({'answer': response['answer']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['DEBUG'] = True\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=\"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\")\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/api/query', methods=['POST'])\n",
    "def query():\n",
    "    document = request.files['document'].read().decode('utf-8')\n",
    "    question = request.form['question']\n",
    "\n",
    "    # Llamada a Langchain\n",
    "    response = qa_document_chain.run(input_document=document, question=question)\n",
    "    \n",
    "    # probando sin almacenar\n",
    "    return jsonify({'answer': response})\n",
    "\n",
    "\n",
    "    # Almacenar en la base de datos (a implementar)\n",
    "\n",
    "    # return jsonify({'answer': response['answer']})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERCERA PRUEBA-YODA\n",
    "A mejorar , estan comentado ciertos intentos , donde p.e. devolvia lo solicitado sobre el texto ingestado, o sea la pregunta sobre el archivo, la respuesta la escribia al revés, que no es exactamente estilo yoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['DEBUG'] = True\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=\"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\")\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/api/query', methods=['POST'])\n",
    "def query():\n",
    "    document = request.files['document'].read().decode('utf-8')\n",
    "    question = request.form['question']\n",
    "    context='contesta como si fueras Yoda'\n",
    "\n",
    "    # Llamada a Langchain\n",
    "    \n",
    "    response = qa_document_chain.run(input_document=document, question=question, \n",
    "                                     context = context)\n",
    "    \n",
    "    # transforma a yoda style\n",
    "    # words = response.split().........ultimo cambio\n",
    "    # yoda_answer = \" \".join(words[::-1]).............ultimo cambio\n",
    "    # Transformar la respuesta al estilo de Yoda\n",
    "    #yoda_response = yoda_style(response['answer'])\n",
    "    return jsonify({'answer': response})\n",
    "    # Devolver la respuesta transformada como JSON\n",
    "    # return jsonify({'answer': yoda_response})\n",
    "\n",
    "    # Almacenar en la base de datos (a implementar)\n",
    "\n",
    "    # return jsonify({'answer': response['answer']})\n",
    "\n",
    "# def yoda_style(answer):\n",
    "#     # Función simple para transformar la respuesta al estilo de Yoda\n",
    "#     words = answer.split()\n",
    "#     yoda_answer = \" \".join(words[::-1])  # Invertir el orden de las palabras\n",
    "#     return yoda_answer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERCERA-bis PRUEBA-YODA\n",
    "He encontrado esta API de YODA(yoda_speak), que tengo que investigar y probar, si es que realmente existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "YODA_API_KEY = 'tu_clave_de_api_de_yoda_speak'\n",
    "\n",
    "def obtener_respuesta_yoda(texto):\n",
    "    url = f'https://yoda-api.appspot.com/api/v1/yodish?text={texto}'\n",
    "    headers = {'X-API-KEY': YODA_API_KEY}\n",
    "    respuesta = requests.get(url, headers=headers)\n",
    "    return respuesta.text\n",
    "\n",
    "@app.route('/yoda', methods=['POST'])\n",
    "def yoda_style():\n",
    "    datos = request.get_json()\n",
    "    texto_usuario = datos.get('texto', '')\n",
    "    respuesta_yoda = obtener_respuesta_yoda(texto_usuario)\n",
    "    return {'respuesta': respuesta_yoda}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 20.5/44.8 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 kB 548.1 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIMERA PRUEBA\n",
    "No funciona bien por el return jsonify....return jsonify({'answer': response['answer']})\n",
    "\n",
    "# SEGUNDA PRUEBA\n",
    "Funciona bien por el siguiente cambio en el anterior script\n",
    "\n",
    "   # probando sin almacenar\n",
    "    return jsonify({'answer': response})\n",
    "\n",
    "\n",
    "    # Almacenar en la base de datos (a implementar)\n",
    "\n",
    "    # return jsonify({'answer': response['answer']})\n",
    "\n",
    "# TERCERA PRUEBA-YODA\n",
    "A mejorar , estan comentado ciertos intentos , donde p.e. devolvia lo solicitado sobre el texto ingestado, o sea la pregunta sobre el archivo, la respuesta la escribia al revés, que no es exactamente estilo yoda\n",
    "\n",
    "# TERCERA-bis PRUEBA-YODA\n",
    "He encontrado esta API de YODA(yoda_speak), que tengo que investigar y probar, si es que realmente existe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
